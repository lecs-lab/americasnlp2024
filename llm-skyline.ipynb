{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Skyline\n",
    "GPT has demonstrated excellent performance on the task using in-context learning. Here, we run a systematic evaluation, in order to provide a *skyline*, i.e. near-optimal automated system. Of course, making OpenAI API calls might not be ideal in real usage for a number of reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Change</th>\n",
       "      <th>Target</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>Formatted</th>\n",
       "      <th>Formatted_Covered</th>\n",
       "      <th>Predicted Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bribri0359</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>ABSNUM:PL</td>\n",
       "      <td>Pûs kapë'ulur</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bribri0360</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TYPE:NEG</td>\n",
       "      <td>Pûs kë̀ kapë̀ne̠wa̠</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bribri0361</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TENSE:PRF_REC</td>\n",
       "      <td>Pûs kapówa̠</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bribri0362</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TENSE:PRF_REC, ABSNUM:PL</td>\n",
       "      <td>Pûs kapóulur</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bribri0363</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TENSE:IPFV_REC, ASPECT:IPFV</td>\n",
       "      <td>Pûs kapö̀wa̠</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>Maya0469</td>\n",
       "      <td>Tene' ma' jbúuleni'</td>\n",
       "      <td>PERSON:3_SI</td>\n",
       "      <td>Leti'e' ma' jbúuli'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td>Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>Maya0470</td>\n",
       "      <td>Tene' ma' jbúuleni'</td>\n",
       "      <td>PERSON:1_PL</td>\n",
       "      <td>To'one' ma' jbúulo'oni'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td>Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>Maya0471</td>\n",
       "      <td>Tene' ma' jbúuleni'</td>\n",
       "      <td>PERSON:2_PL</td>\n",
       "      <td>Te'exe' ma' jbúule'exi'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td>Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>Maya0121</td>\n",
       "      <td>Táan a bin koonol tu k'íiwikil koonol</td>\n",
       "      <td>TYPE:NEG</td>\n",
       "      <td>Ma' táan a bin koonol tu k'íiwikil koonoli'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0121\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td>Id: Maya0121\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>Maya0122</td>\n",
       "      <td>Táan a bin koonol tu k'íiwikil koonol</td>\n",
       "      <td>SUBTYPE:INT</td>\n",
       "      <td>Táan wáaj a bin koonol tu k'íiwikil koonol</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0122\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td>Id: Maya0122\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2675 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                 Source  \\\n",
       "0     Bribri0359                           Pûs kapë'wa̠   \n",
       "1     Bribri0360                           Pûs kapë'wa̠   \n",
       "2     Bribri0361                           Pûs kapë'wa̠   \n",
       "3     Bribri0362                           Pûs kapë'wa̠   \n",
       "4     Bribri0363                           Pûs kapë'wa̠   \n",
       "...          ...                                    ...   \n",
       "2670    Maya0469                    Tene' ma' jbúuleni'   \n",
       "2671    Maya0470                    Tene' ma' jbúuleni'   \n",
       "2672    Maya0471                    Tene' ma' jbúuleni'   \n",
       "2673    Maya0121  Táan a bin koonol tu k'íiwikil koonol   \n",
       "2674    Maya0122  Táan a bin koonol tu k'íiwikil koonol   \n",
       "\n",
       "                           Change  \\\n",
       "0                       ABSNUM:PL   \n",
       "1                        TYPE:NEG   \n",
       "2                   TENSE:PRF_REC   \n",
       "3        TENSE:PRF_REC, ABSNUM:PL   \n",
       "4     TENSE:IPFV_REC, ASPECT:IPFV   \n",
       "...                           ...   \n",
       "2670                  PERSON:3_SI   \n",
       "2671                  PERSON:1_PL   \n",
       "2672                  PERSON:2_PL   \n",
       "2673                     TYPE:NEG   \n",
       "2674                  SUBTYPE:INT   \n",
       "\n",
       "                                           Target language  split  \\\n",
       "0                                   Pûs kapë'ulur   bribri    dev   \n",
       "1                             Pûs kë̀ kapë̀ne̠wa̠   bribri    dev   \n",
       "2                                     Pûs kapówa̠   bribri    dev   \n",
       "3                                    Pûs kapóulur   bribri    dev   \n",
       "4                                    Pûs kapö̀wa̠   bribri    dev   \n",
       "...                                           ...      ...    ...   \n",
       "2670                          Leti'e' ma' jbúuli'     maya  train   \n",
       "2671                      To'one' ma' jbúulo'oni'     maya  train   \n",
       "2672                      Te'exe' ma' jbúule'exi'     maya  train   \n",
       "2673  Ma' táan a bin koonol tu k'íiwikil koonoli'     maya  train   \n",
       "2674   Táan wáaj a bin koonol tu k'íiwikil koonol     maya  train   \n",
       "\n",
       "                                              Formatted  \\\n",
       "0     Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "1     Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "2     Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "3     Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "4     Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "...                                                 ...   \n",
       "2670  Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
       "2671  Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
       "2672  Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
       "2673  Id: Maya0121\\nSource: Táan a bin koonol tu k'í...   \n",
       "2674  Id: Maya0122\\nSource: Táan a bin koonol tu k'í...   \n",
       "\n",
       "                                      Formatted_Covered Predicted Target  \n",
       "0     Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "1     Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "2     Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "3     Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "4     Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "...                                                 ...              ...  \n",
       "2670  Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...                   \n",
       "2671  Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...                   \n",
       "2672  Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...                   \n",
       "2673  Id: Maya0121\\nSource: Táan a bin koonol tu k'í...                   \n",
       "2674  Id: Maya0122\\nSource: Táan a bin koonol tu k'í...                   \n",
       "\n",
       "[2675 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read all of the data into a single combined DF\n",
    "folder_path = 'americasnlp2024/ST2_EducationalMaterials/data/'\n",
    "all_data = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.tsv'):\n",
    "        split_df = pd.read_csv(os.path.join(folder_path, filename), delimiter='\\t')\n",
    "        [split_df['language'], split_df['split']] = filename[:-4].split(\"-\")\n",
    "        all_data.append(split_df)\n",
    "\n",
    "df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# We'll add spaces between letters to avoid tokenization issues\n",
    "df['Formatted'] = df.apply(lambda row: f\"Id: {row['ID']}\\nSource: {row['Source']}\\nChange: {row['Change']}\\nTarget: {row['Target']}\", axis=1)\n",
    "df['Formatted_Covered'] = df.apply(lambda row: f\"Id: {row['ID']}\\nSource: {row['Source']}\\nChange: {row['Change']}\\nTarget: \", axis=1)\n",
    "df['Predicted Target'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pûs kë̀ ku̠ kapë'wa̠\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def remove_single_spaces(text: str) -> str:\n",
    "    # Replace single spaces between letters with no space\n",
    "    return re.sub(\"\\s+\", \" \", re.sub(r'(?<=\\w|\\') (?=\\w|\\')', '', text))\n",
    "\n",
    "# Fixes unattached diacritics\n",
    "def attach_diacritics(text: str) -> str:\n",
    "    # Function to reorder each match\n",
    "    def reorder(match):\n",
    "        char, diacritic = match.groups()\n",
    "        # Return the reordered string with the diacritic attached to the character\n",
    "        return char + diacritic\n",
    "    \n",
    "    # Regular expression to find a character followed by a space and then the diacritic\n",
    "    pattern = r'(\\w) ([ ̀ ̠])'\n",
    "    # Replace occurrences found by the pattern with the reordered version\n",
    "    adjusted_text = re.sub(pattern, reorder, text)\n",
    "    \n",
    "    return adjusted_text\n",
    "\n",
    "remove_single_spaces(attach_diacritics(\"P û s   k ë ̀   k u ̠   k a p ë ' w a ̠\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if 'api_key' not in vars():\n",
    "    api_key = input(\"OpenAI API Key:\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "def run_prompt_full_context(lang, log_file, test_IDs=None):\n",
    "    \"\"\"Runs a GPT prompt for a specified row in the dev/test set. Uses the entire `train` split as context.\n",
    "\n",
    "    Args:\n",
    "        lang: 'bribri' | 'guarani' | 'maya'\n",
    "        test_ID The ID of a row in the dev/test set to run inference on.\n",
    "    \"\"\"\n",
    "    train_split = df[(df['language'] == lang) & (df['split'] == 'train')]\n",
    "\n",
    "    if test_IDs is not None:\n",
    "        test_sentences = df[df['ID'].isin(test_IDs)]\n",
    "    else:\n",
    "        test_sentences = df[(df['language'] == lang) & (df['split'] == 'dev')]\n",
    "\n",
    "    system_prompt = f\"You are an expert in the {lang.capitalize()} language. You are creating education materials by taking a given sentence in {lang.capitalize()} and a label indicating a change in one or more linguistic features, and outputting the sentence transformed by changing that feature.\"\n",
    "    context = '\\n\\n'.join(train_split['Formatted'])\n",
    "    test_examples = '\\n\\n'.join(test_sentences['Formatted_Covered'])\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"Below are examples of a sentence in {lang.capitalize()}, the linguistic change, and the target sentence after applying the change.\n",
    "    \n",
    "{context}\n",
    "\n",
    "Below is a list of similar examples, where the source sentence and linguistic change are given, and the output sentence is not known. For each example, please output only the id and target sentence values, as in\n",
    "\n",
    "ID: some id\n",
    "Target: sentence after applying the change\n",
    "\n",
    "\n",
    "Do not output any additional text, and do not output the Source or Change fields. This is very important, take your time and do not mess up or I will lose my job.\n",
    "\n",
    "{test_examples}\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-4-turbo-preview\",\n",
    "        model=\"gpt-4-turbo-2024-04-09\",\n",
    "\n",
    "        #model = \"gpt-3.5-turbo-0125\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "        seed=430\n",
    "    )\n",
    "    print(completion.usage)\n",
    "    print(completion.model)\n",
    "\n",
    "    pattern = r\"I[dD]: (\\S+)\\nTarget: (.*)(\\n|$)\"\n",
    "    resp = completion.choices[0].message.content\n",
    "    \n",
    "    with open(log_file, 'a') as log:\n",
    "        log.write(\"\\n\\nPROMPT:\\n\" + prompt)\n",
    "        log.write(\"\\nRESPONSE:\\n\" + resp)\n",
    "\n",
    "    matches = re.findall(pattern, resp, re.M)\n",
    "    matches_dict = dict()\n",
    "    for match in matches:\n",
    "        matches_dict[match[0]] = match[1] # remove_single_spaces(attach_diacritics(match[1]))\n",
    "    return matches_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m     df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaya\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../preds/chatgpt/fc_chunksize_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/maya-dev-preds.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 21\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mtest_full_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m preds\n",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m, in \u001b[0;36mtest_full_context\u001b[0;34m(chunk_size, df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_full_context\u001b[39m(chunk_size, df):\n\u001b[1;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m language \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbribri\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mguarani\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaya\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      6\u001b[0m         lang_test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m language) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(math\u001b[38;5;241m.\u001b[39mceil(lang_test_size \u001b[38;5;241m/\u001b[39m chunk_size))):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/tqdm/notebook.py:233\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    232\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/tqdm/notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def test_full_context(chunk_size, df):\n",
    "    df = df.copy(deep=True)\n",
    "    for language in tqdm(['bribri', 'guarani', 'maya']):\n",
    "        lang_test_size = len(df[(df['language'] == language) & (df['split'] == 'dev')])\n",
    "\n",
    "        for chunk in tqdm(range(math.ceil(lang_test_size / chunk_size))):\n",
    "            print(f\"Testing indices {chunk*chunk_size} through {(chunk+1)*chunk_size}\")\n",
    "            test_chunk = df[(df['language'] == language) & (df['split'] == 'dev')]['ID'].values[chunk*chunk_size: (chunk+1)*chunk_size]\n",
    "            pred_dict = run_prompt_full_context(lang=language, test_IDs=test_chunk, log_file=f\"./{language}.log\")\n",
    "            for pred_id, pred_string in pred_dict.items():\n",
    "                df.loc[df['ID'] == pred_id, 'Predicted Target'] = pred_string\n",
    "\n",
    "    df[(df['language'] == 'bribri') & (df['split'] == 'dev')].to_csv(f\"../preds/chatgpt/fc_chunksize_{chunk_size}/bribri-dev-preds.tsv\", sep=\"\\t\")\n",
    "    df[(df['language'] == 'guarani') & (df['split'] == 'dev')].to_csv(f\"../preds/chatgpt/fc_chunksize_{chunk_size}/guarani-dev-preds.tsv\", sep=\"\\t\")\n",
    "    df[(df['language'] == 'maya') & (df['split'] == 'dev')].to_csv(f\"../preds/chatgpt/fc_chunksize_{chunk_size}/maya-dev-preds.tsv\", sep=\"\\t\")\n",
    "\n",
    "    return df\n",
    "\n",
    "preds = test_full_context(chunk_size=80, df=df)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mtest_full_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m preds\n",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m, in \u001b[0;36mtest_full_context\u001b[0;34m(chunk_size, df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_full_context\u001b[39m(chunk_size, df):\n\u001b[1;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m language \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbribri\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mguarani\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaya\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      6\u001b[0m         lang_test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m language) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(math\u001b[38;5;241m.\u001b[39mceil(lang_test_size \u001b[38;5;241m/\u001b[39m chunk_size))):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/tqdm/notebook.py:233\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    232\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/tqdm/notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "preds = test_full_context(chunk_size=20, df=df)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "Rather than passing full context, let's try selecting informative examples for each sentence. First, we'll split up sentences based on the linguistic change tags. Then, for each group of sentences, we'll retrieve train sentences with similar tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x13877e480>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/clairepost/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/tqdm/std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/clairepost/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/tqdm/notebook.py\", line 278, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TENSE:PRF_REC, ABSNUM:PL' 'TYPE:NEG, TENSE:PRF_PROG']\n",
      "Below are examples of a sentence in Bribri, the linguistic change, and the target sentence after applying the change.\n",
      "    \n",
      "Id: Bribri0303\n",
      "Source: Ye' shka'\n",
      "Change: TYPE:NEG, TENSE:PRF_PROG\n",
      "Target: Ye' kë̀ ku̠'bak shkö́k\n",
      "\n",
      "Id: Bribri0962\n",
      "Source: Ye' tö i sík\n",
      "Change: TYPE:NEG, TENSE:PRF_PROG\n",
      "Target: Ye' kë̀ ku̠'bak i skö́k\n",
      "\n",
      "Id: Bribri0771\n",
      "Source: Ye' dör àrros tó̠ ñè̠\n",
      "Change: TYPE:NEG, TENSE:PRF_PROG\n",
      "Target: Ye' kë̀ ku̠'bak àrros ta̠ú̠k ñè̠\n",
      "\n",
      "Id: Bribri0493\n",
      "Source: Ye' tö kàsir të'\n",
      "Change: TYPE:NEG, TENSE:PRF_PROG\n",
      "Target: Ye' kë̀ ku̠'bak kàsir tö́k\n",
      "\n",
      "Id: Bribri0899\n",
      "Source: Ie' tö bö' yë'stsa̠\n",
      "Change: TENSE:PRF_REC, ABSNUM:PL\n",
      "Target: Ie' tö bö' yéulur\n",
      "\n",
      "Id: Bribri0380\n",
      "Source: Ie' dúwa̠\n",
      "Change: TYPE:NEG, TENSE:PRF_PROG\n",
      "Target: Ie' kë̀ ku'bak dawö́kwa̠\n",
      "\n",
      "Id: Bribri0611\n",
      "Source: Be' dör ye' tsí bi'\n",
      "Change: TYPE:NEG, TENSE:PRF_PROG\n",
      "Target: Be' kë̀ ku̠'bak ye' tsí biö́k\n",
      "\n",
      "Id: Bribri0691\n",
      "Source: Chìchi tö Po'tak kö'\n",
      "Change: TYPE:NEG, TENSE:PRF_PROG\n",
      "Target: Chìchi kë̀ ku̠'bak Po'tak kuö́k\n",
      "\n",
      "Below is a list of similar examples, where the source sentence and linguistic change are given, and the output sentence is not known. For each example, please output only the id and target sentence values, as in\n",
      "\n",
      "ID: some id\n",
      "Target: sentence after applying the change\n",
      "\n",
      "\n",
      "Do not output any additional text, and do not output the Source or Change fields. This is very important, take your time and do not mess up or I will lose my job.\n",
      "\n",
      "Id: Bribri0362\n",
      "Source: Pûs kapë'wa̠\n",
      "Change: TENSE:PRF_REC, ABSNUM:PL\n",
      "Target: \n",
      "\n",
      "Id: Bribri0367\n",
      "Source: Pûs kapë'wa̠\n",
      "Change: TYPE:NEG, TENSE:PRF_PROG\n",
      "Target: \n",
      "    \n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `gpt-4-turbo-preview` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m         matches_dict[match[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m match[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m matches_dict\n\u001b[0;32m---> 63\u001b[0m \u001b[43mrun_prompt_naive_retrieval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbribri\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_IDs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBribri0362\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBribri0367\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 41\u001b[0m, in \u001b[0;36mrun_prompt_naive_retrieval\u001b[0;34m(lang, test_IDs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mBelow are examples of a sentence in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, the linguistic change, and the target sentence after applying the change.\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124m    \u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mtest_examples\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prompt)\n\u001b[0;32m---> 41\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4-turbo-preview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m430\u001b[39;49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39musage)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/openai/resources/chat/completions.py:667\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/openai/_base_client.py:1213\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1201\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1210\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1211\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1212\u001b[0m     )\n\u001b[0;32m-> 1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/openai/_base_client.py:902\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    895\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    901\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyfomaEnv/lib/python3.12/site-packages/openai/_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    990\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    992\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    996\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    997\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1000\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1001\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': 'The model `gpt-4-turbo-preview` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "def run_prompt_naive_retrieval(lang, test_IDs):\n",
    "    \"\"\"Runs a GPT prompt for a specified row in the dev/test set. Retrieves items from the `train` split that have the same change tags.\n",
    "\n",
    "    Args:\n",
    "        lang: 'bribri' | 'guarani' | 'maya'\n",
    "        test_ID The ID of a row in the dev/test set to run inference on.\n",
    "    \"\"\"\n",
    "    train_split = df[(df['language'] == lang) & (df['split'] == 'train')]\n",
    "\n",
    "    assert(test_IDs is not None)\n",
    "\n",
    "    test_sentences = df[df['ID'].isin(test_IDs)]\n",
    "\n",
    "    # Determine the tags that appear in the test sentences\n",
    "    test_change_tags = test_sentences['Change'].unique()\n",
    "    print(test_change_tags)\n",
    "    filtered_train = train_split[train_split['Change'].isin(test_change_tags)]\n",
    "\n",
    "    system_prompt = f\"You are an expert in the {lang.capitalize()} language. You are creating education materials by taking a given sentence in {lang.capitalize()} and a label indicating a change in one or more linguistic features, and outputting the sentence transformed by changing that feature. All Bribri text is seperated by spaces.\"\n",
    "    context = '\\n\\n'.join(filtered_train['Formatted'])\n",
    "    test_examples = '\\n\\n'.join(test_sentences['Formatted_Covered'])\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"Below are examples of a sentence in {lang.capitalize()}, the linguistic change, and the target sentence after applying the change.\n",
    "    \n",
    "{context}\n",
    "\n",
    "Below is a list of similar examples, where the source sentence and linguistic change are given, and the output sentence is not known. For each example, please output only the id and target sentence values, as in\n",
    "\n",
    "ID: some id\n",
    "Target: sentence after applying the change\n",
    "\n",
    "\n",
    "Do not output any additional text, and do not output the Source or Change fields. This is very important, take your time and do not mess up or I will lose my job.\n",
    "\n",
    "{test_examples}\n",
    "    \"\"\"\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        seed=430\n",
    "    )\n",
    "    print(completion.usage)\n",
    "    print(completion.model)\n",
    "\n",
    "    pattern = r\"I[dD]: (\\S+)\\nTarget: (.*)(\\n|$)\"\n",
    "    resp = completion.choices[0].message.content\n",
    "    print(resp)\n",
    "    matches = re.findall(pattern, resp, re.M)\n",
    "    matches_dict = dict()\n",
    "    for match in matches:\n",
    "        matches_dict[match[0]] = match[1]\n",
    "    return matches_dict\n",
    "\n",
    "run_prompt_naive_retrieval(\"bribri\", test_IDs=[\"Bribri0362\", \"Bribri0367\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TENSE:PRF_REC', 'ABSNUM:PL', 'TENSE:PRF_REC, ABSNUM:PL']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=834, total_tokens=854)\n",
      "gpt-3.5-turbo-0125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bribri0362': \"Pûs kapë'wé̠\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_prompt_smart_retrieval(lang, log_file, test_IDs):\n",
    "    \"\"\"Runs a GPT prompt for a specified row in the dev/test set. Retrieves items from the `train` split that have the same change tags and sub-change tags\n",
    "\n",
    "    Args:\n",
    "        lang: 'bribri' | 'guarani' | 'maya'\n",
    "        test_ID The ID of a row in the dev/test set to run inference on.\n",
    "    \"\"\"\n",
    "    train_split = df[(df['language'] == lang) & (df['split'] == 'train')]\n",
    "\n",
    "    assert(test_IDs is not None)\n",
    "\n",
    "    test_sentences = df[df['ID'].isin(test_IDs)]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for test_sent in test_sentences.iterrows():\n",
    "        test_sent=test_sent[1]\n",
    "\n",
    "        # Determine the tags that appear in the test sentences\n",
    "        test_change_tags = test_sent['Change'].split(\", \")\n",
    "        test_change_tags.append(test_sent['Change'])\n",
    "        print(test_change_tags)\n",
    "        filtered_train = train_split[train_split['Change'].isin(test_change_tags)]\n",
    "\n",
    "        system_prompt = f\"You are an expert in the {lang.capitalize()} language. You are creating education materials by taking a given sentence in {lang.capitalize()} and a label indicating a change in one or more linguistic features, and outputting the sentence transformed by changing that feature. All Bribri text is seperated by spaces.\"\n",
    "        context = '\\n\\n'.join(filtered_train['Formatted'])\n",
    "        test_examples = '\\n\\n' + test_sent['Formatted_Covered']\n",
    "\n",
    "\n",
    "        prompt = f\"\"\"Below are examples of a sentence in {lang.capitalize()}, the linguistic change, and the target sentence after applying the change.\n",
    "        \n",
    "        {context}\n",
    "\n",
    "        Below is a similar example, where the source sentence and linguistic change are given, and the output sentence is not known. For this example, please output only the id and target sentence values, as in\n",
    "\n",
    "        ID: some id\n",
    "        Target: sentence after applying the change\n",
    "\n",
    "\n",
    "        Do not output any additional text, and do not output the Source or Change fields. This is very important, take your time and do not mess up or I will lose my job.\n",
    "\n",
    "        {test_examples}\n",
    "        \"\"\"\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            #model=\"gpt-4-0613\",\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            top_p=1,\n",
    "            seed=430\n",
    "        )\n",
    "        print(completion.usage)\n",
    "        print(completion.model)\n",
    "\n",
    "        pattern = r\"I[dD]: (\\S+)\\nTarget: (.*)(\\n|$)\"\n",
    "        resp = completion.choices[0].message.content\n",
    "    \n",
    "        with open(log_file, 'a') as log:\n",
    "            log.write(\"\\n\\nPROMPT:\\n\" + prompt)\n",
    "            log.write(\"\\nRESPONSE:\\n\" + resp)\n",
    "\n",
    "        matches = re.findall(pattern, resp, re.M)\n",
    "        matches_dict = dict()\n",
    "        for match in matches:\n",
    "            matches_dict[match[0]] = remove_single_spaces(attach_diacritics(match[1]))\n",
    "           # results[match[0]] = remove_single_spaces(attach_diacritics(match[1]))- for when we add in the smart split\n",
    "            results[match[0]] = match[1]\n",
    "\n",
    "\n",
    "    return results\n",
    "# return matches_dict\n",
    "\n",
    "run_prompt_smart_retrieval(\"bribri\", \"test.log\", test_IDs=[\"Bribri0362\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing indices 0 through 80\n",
      "['TYPE:AFF', 'TYPE:AFF']\n",
      "CompletionUsage(completion_tokens=15, prompt_tokens=740, total_tokens=755)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:FUT_SIM', 'TENSE:FUT_SIM']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=1123, total_tokens=1140)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_INC', 'PERSON:1_PL_INC']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=737, total_tokens=756)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_SI', 'PERSON:1_SI']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=696, total_tokens=713)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=545, total_tokens=563)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=1038, total_tokens=1055)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:AFF', 'TYPE:AFF']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=741, total_tokens=758)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=649, total_tokens=668)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_SI', 'PERSON:1_SI']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=697, total_tokens=713)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PAS_REC', 'TENSE:PAS_REC']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=727, total_tokens=746)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PRE_SIM', 'TENSE:PRE_SIM']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=788, total_tokens=806)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PAS_REC', 'TENSE:PAS_REC']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=726, total_tokens=745)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_INC', 'PERSON:1_PL_INC']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=737, total_tokens=755)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_EXC', 'PERSON:1_PL_EXC']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=380, total_tokens=396)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:FUT_SIM', 'TENSE:FUT_SIM']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=1123, total_tokens=1141)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=1175, total_tokens=1194)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PRE_SIM', 'TENSE:PRE_SIM']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=787, total_tokens=804)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:AFF', 'TYPE:AFF']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=747, total_tokens=770)\n",
      "gpt-3.5-turbo-0125\n",
      "['ASPECT:IPFV', 'ASPECT:IPFV']\n",
      "CompletionUsage(completion_tokens=27, prompt_tokens=841, total_tokens=868)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PRE_SIM', 'TENSE:PRE_SIM']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=794, total_tokens=814)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=1045, total_tokens=1070)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_INC', 'PERSON:1_PL_INC']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=748, total_tokens=776)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_EXC', 'PERSON:1_PL_EXC']\n",
      "CompletionUsage(completion_tokens=26, prompt_tokens=391, total_tokens=417)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=1186, total_tokens=1214)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:FUT_SIM', 'TENSE:FUT_SIM']\n",
      "CompletionUsage(completion_tokens=29, prompt_tokens=1134, total_tokens=1163)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PAS_PLU', 'TENSE:PAS_PLU']\n",
      "CompletionUsage(completion_tokens=32, prompt_tokens=770, total_tokens=802)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:FUT_SIM', 'TENSE:FUT_SIM']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=1126, total_tokens=1144)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PRE_SIM', 'TENSE:PRE_SIM']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=790, total_tokens=808)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=651, total_tokens=673)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_INC', 'PERSON:1_PL_INC']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=740, total_tokens=760)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_EXC', 'PERSON:1_PL_EXC']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=383, total_tokens=401)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:AFF', 'TYPE:AFF']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=743, total_tokens=762)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=30, prompt_tokens=1188, total_tokens=1218)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=29, prompt_tokens=558, total_tokens=587)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_INC', 'PERSON:1_PL_INC']\n",
      "CompletionUsage(completion_tokens=30, prompt_tokens=750, total_tokens=780)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_EXC', 'PERSON:1_PL_EXC']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=393, total_tokens=421)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=1177, total_tokens=1197)\n",
      "gpt-3.5-turbo-0125\n",
      "['ASPECT:IPFV', 'ASPECT:IPFV']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=836, total_tokens=858)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PAS_PLU', 'TENSE:PAS_PLU']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=761, total_tokens=784)\n",
      "gpt-3.5-turbo-0125\n",
      "['ASPECT:INM', 'ASPECT:INM']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=409, total_tokens=431)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_INC', 'PERSON:1_PL_INC']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=739, total_tokens=756)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_EXC', 'PERSON:1_PL_EXC']\n",
      "CompletionUsage(completion_tokens=15, prompt_tokens=382, total_tokens=397)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:AFF', 'TYPE:AFF']\n",
      "CompletionUsage(completion_tokens=14, prompt_tokens=737, total_tokens=751)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_INC', 'PERSON:1_PL_INC']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=734, total_tokens=752)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=542, total_tokens=558)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=15, prompt_tokens=1035, total_tokens=1050)\n",
      "gpt-3.5-turbo-0125\n",
      "['ASPECT:IPFV', 'ASPECT:IPFV']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=831, total_tokens=848)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=27, prompt_tokens=1184, total_tokens=1211)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=26, prompt_tokens=1047, total_tokens=1073)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=27, prompt_tokens=554, total_tokens=581)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_SI', 'PERSON:1_SI']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=705, total_tokens=730)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:FUT_SIM', 'TENSE:FUT_SIM']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=1132, total_tokens=1157)\n",
      "gpt-3.5-turbo-0125\n",
      "['ASPECT:IPFV', 'ASPECT:IPFV']\n",
      "CompletionUsage(completion_tokens=29, prompt_tokens=843, total_tokens=872)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:AFF', 'TYPE:AFF']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=739, total_tokens=755)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PAS_REC', 'TENSE:PAS_REC']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=725, total_tokens=743)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=1037, total_tokens=1053)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_SI', 'PERSON:1_SI']\n",
      "CompletionUsage(completion_tokens=15, prompt_tokens=695, total_tokens=710)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_INC', 'PERSON:1_PL_INC']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=736, total_tokens=753)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:FUT_SIM', 'TENSE:FUT_SIM']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=1122, total_tokens=1139)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=1174, total_tokens=1191)\n",
      "gpt-3.5-turbo-0125\n",
      "['ASPECT:IPFV', 'ASPECT:IPFV']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=833, total_tokens=852)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=1037, total_tokens=1053)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_SI', 'PERSON:1_SI']\n",
      "CompletionUsage(completion_tokens=15, prompt_tokens=695, total_tokens=710)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:FUT_SIM', 'TENSE:FUT_SIM']\n",
      "CompletionUsage(completion_tokens=15, prompt_tokens=1122, total_tokens=1137)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PAS_PLU', 'TENSE:PAS_PLU']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=758, total_tokens=776)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PAS_IMP', 'TENSE:PAS_IMP']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=487, total_tokens=503)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=1038, total_tokens=1054)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=334, total_tokens=351)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=1175, total_tokens=1194)\n",
      "gpt-3.5-turbo-0125\n",
      "['ASPECT:IPFV', 'ASPECT:IPFV']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=834, total_tokens=854)\n",
      "gpt-3.5-turbo-0125\n",
      "['ASPECT:INM', 'ASPECT:INM']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=407, total_tokens=427)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL_EXC', 'PERSON:1_PL_EXC']\n",
      "CompletionUsage(completion_tokens=15, prompt_tokens=380, total_tokens=395)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_SI', 'PERSON:1_SI']\n",
      "CompletionUsage(completion_tokens=15, prompt_tokens=696, total_tokens=711)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=1183, total_tokens=1208)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=342, total_tokens=367)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:FUT_SIM', 'TENSE:FUT_SIM']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=1131, total_tokens=1154)\n",
      "gpt-3.5-turbo-0125\n",
      "['ASPECT:IPFV', 'ASPECT:IPFV']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=842, total_tokens=870)\n",
      "gpt-3.5-turbo-0125\n",
      "['TENSE:PAS_IMP', 'TENSE:PAS_IMP']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=496, total_tokens=521)\n",
      "gpt-3.5-turbo-0125\n",
      "['ASPECT:INM', 'ASPECT:INM']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=415, total_tokens=443)\n",
      "gpt-3.5-turbo-0125\n",
      "Testing indices 0 through 80\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=3602, total_tokens=3625)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4627, total_tokens=4648)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=3547, total_tokens=3570)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=1311, total_tokens=1330)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=2088, total_tokens=2107)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=1315, total_tokens=1338)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=2092, total_tokens=2115)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=34, prompt_tokens=1326, total_tokens=1360)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=34, prompt_tokens=2103, total_tokens=2137)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=3542, total_tokens=3560)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=4174, total_tokens=4199)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=4695, total_tokens=4723)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=27, prompt_tokens=4628, total_tokens=4655)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4623, total_tokens=4644)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4690, total_tokens=4712)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=3543, total_tokens=3562)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=4169, total_tokens=4188)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4690, total_tokens=4711)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4623, total_tokens=4644)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=3598, total_tokens=3617)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=2087, total_tokens=2105)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=1310, total_tokens=1327)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=4169, total_tokens=4188)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4623, total_tokens=4644)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4690, total_tokens=4712)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=14, prompt_tokens=3538, total_tokens=3552)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=1321, total_tokens=1349)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=29, prompt_tokens=2098, total_tokens=2127)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=1315, total_tokens=1336)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=2092, total_tokens=2116)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=3545, total_tokens=3567)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4171, total_tokens=4193)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=3600, total_tokens=3622)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=4692, total_tokens=4716)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=4692, total_tokens=4716)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=1316, total_tokens=1339)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=2093, total_tokens=2117)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=26, prompt_tokens=3550, total_tokens=3576)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=3540, total_tokens=3556)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=4166, total_tokens=4182)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=4687, total_tokens=4706)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=4620, total_tokens=4638)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=16, prompt_tokens=3595, total_tokens=3611)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=1321, total_tokens=1349)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=29, prompt_tokens=2098, total_tokens=2127)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=27, prompt_tokens=1318, total_tokens=1345)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=27, prompt_tokens=1318, total_tokens=1345)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=33, prompt_tokens=2102, total_tokens=2135)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'SUBTYPE:INT', 'TYPE:NEG, SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=36, prompt_tokens=3497, total_tokens=3533)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=1311, total_tokens=1330)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'PERSON:1_SI', 'SUBTYPE:INT, PERSON:1_SI']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=2514, total_tokens=2533)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=30, prompt_tokens=2099, total_tokens=2129)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'SUBTYPE:INT', 'TYPE:NEG, SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=33, prompt_tokens=3494, total_tokens=3527)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=3545, total_tokens=3567)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4171, total_tokens=4193)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=3600, total_tokens=3623)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=4625, total_tokens=4648)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4692, total_tokens=4713)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=3544, total_tokens=3565)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4170, total_tokens=4192)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=3599, total_tokens=3621)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=4624, total_tokens=4648)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=4691, total_tokens=4715)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=4168, total_tokens=4186)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=3597, total_tokens=3616)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=4622, total_tokens=4641)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=2089, total_tokens=2110)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'ASPECT:NA', 'TYPE:NEG, ASPECT:NA']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=1317, total_tokens=1334)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=4169, total_tokens=4189)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=36, prompt_tokens=1328, total_tokens=1364)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=36, prompt_tokens=2105, total_tokens=2141)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4171, total_tokens=4192)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=3600, total_tokens=3621)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=4625, total_tokens=4650)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=4692, total_tokens=4716)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=3543, total_tokens=3562)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=4169, total_tokens=4189)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=3598, total_tokens=3619)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4623, total_tokens=4645)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=26, prompt_tokens=4690, total_tokens=4716)\n",
      "gpt-3.5-turbo-0125\n",
      "Testing indices 80 through 160\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=1319, total_tokens=1347)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'SUBTYPE:INT', 'TYPE:NEG, SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=3491, total_tokens=3519)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=3546, total_tokens=3567)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=3601, total_tokens=3623)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=4167, total_tokens=4185)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=3596, total_tokens=3614)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=4621, total_tokens=4640)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4688, total_tokens=4709)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=1312, total_tokens=1329)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=2089, total_tokens=2110)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_SI', 'PERSON:1_SI']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=595, total_tokens=619)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=4174, total_tokens=4198)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=27, prompt_tokens=4695, total_tokens=4722)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=26, prompt_tokens=4628, total_tokens=4654)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=30, prompt_tokens=3553, total_tokens=3583)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=30, prompt_tokens=3553, total_tokens=3583)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=31, prompt_tokens=3608, total_tokens=3639)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=33, prompt_tokens=4633, total_tokens=4666)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=30, prompt_tokens=2099, total_tokens=2129)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'SUBTYPE:INT', 'TYPE:NEG, SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=30, prompt_tokens=3494, total_tokens=3524)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=30, prompt_tokens=1322, total_tokens=1352)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=3545, total_tokens=3566)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=4692, total_tokens=4715)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4625, total_tokens=4647)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'TYPE:NEG']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=1319, total_tokens=1343)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'SUBTYPE:INT', 'TYPE:NEG, SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=26, prompt_tokens=3491, total_tokens=3517)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=29, prompt_tokens=4632, total_tokens=4661)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=30, prompt_tokens=4699, total_tokens=4729)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'SUBTYPE:INT']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=2096, total_tokens=2124)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4171, total_tokens=4192)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=4692, total_tokens=4716)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=4625, total_tokens=4648)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=3544, total_tokens=3565)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=4170, total_tokens=4189)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=3599, total_tokens=3620)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4624, total_tokens=4646)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4691, total_tokens=4713)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=3544, total_tokens=3564)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4170, total_tokens=4191)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=3599, total_tokens=3619)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=24, prompt_tokens=4691, total_tokens=4715)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4624, total_tokens=4646)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=3549, total_tokens=3574)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=4175, total_tokens=4200)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=4696, total_tokens=4724)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=27, prompt_tokens=4629, total_tokens=4656)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=3544, total_tokens=3564)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4170, total_tokens=4191)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=3599, total_tokens=3621)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=4624, total_tokens=4647)\n",
      "gpt-3.5-turbo-0125\n",
      "['SUBTYPE:INT', 'PERSON:2_SI', 'SUBTYPE:INT, PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=23, prompt_tokens=5480, total_tokens=5503)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=4169, total_tokens=4190)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4623, total_tokens=4645)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=21, prompt_tokens=3598, total_tokens=3619)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=22, prompt_tokens=4690, total_tokens=4712)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=3542, total_tokens=3560)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=4168, total_tokens=4186)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=4689, total_tokens=4709)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=20, prompt_tokens=4622, total_tokens=4642)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=19, prompt_tokens=4169, total_tokens=4188)\n",
      "gpt-3.5-turbo-0125\n",
      "['STATUS:ICM', 'ASPECT:PRG', 'TENSE:PRE_SIM', 'STATUS:ICM, ASPECT:PRG, TENSE:PRE_SIM']\n",
      "CompletionUsage(completion_tokens=37, prompt_tokens=353, total_tokens=390)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_SI', 'PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=26, prompt_tokens=4176, total_tokens=4202)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=4630, total_tokens=4658)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:3_PL', 'PERSON:3_PL']\n",
      "CompletionUsage(completion_tokens=29, prompt_tokens=4697, total_tokens=4726)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:1_PL', 'PERSON:1_PL']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=3597, total_tokens=3614)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_PL', 'PERSON:2_PL']\n",
      "CompletionUsage(completion_tokens=17, prompt_tokens=4622, total_tokens=4639)\n",
      "gpt-3.5-turbo-0125\n",
      "['PERSON:2_SI', 'PERSON:2_SI']\n",
      "CompletionUsage(completion_tokens=18, prompt_tokens=3542, total_tokens=3560)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'MODE:SUB', 'ADVTENSE:NA', 'PERSON:3_SI', 'TYPE:NEG, MODE:SUB, ADVTENSE:NA, PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=5282, total_tokens=5307)\n",
      "gpt-3.5-turbo-0125\n",
      "['TYPE:NEG', 'SUBTYPE:INT', 'MODE:SUB', 'ADVTENSE:NA', 'PERSON:3_SI', 'TYPE:NEG, SUBTYPE:INT, MODE:SUB, ADVTENSE:NA, PERSON:3_SI']\n",
      "CompletionUsage(completion_tokens=25, prompt_tokens=7160, total_tokens=7185)\n",
      "gpt-3.5-turbo-0125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Change</th>\n",
       "      <th>Target</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>Formatted</th>\n",
       "      <th>Formatted_Covered</th>\n",
       "      <th>Predicted Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bribri0359</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>ABSNUM:PL</td>\n",
       "      <td>Pûs kapë'ulur</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bribri0360</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TYPE:NEG</td>\n",
       "      <td>Pûs kë̀ kapë̀ne̠wa̠</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bribri0361</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TENSE:PRF_REC</td>\n",
       "      <td>Pûs kapówa̠</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bribri0362</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TENSE:PRF_REC, ABSNUM:PL</td>\n",
       "      <td>Pûs kapóulur</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bribri0363</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TENSE:IPFV_REC, ASPECT:IPFV</td>\n",
       "      <td>Pûs kapö̀wa̠</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>Maya0469</td>\n",
       "      <td>Tene' ma' jbúuleni'</td>\n",
       "      <td>PERSON:3_SI</td>\n",
       "      <td>Leti'e' ma' jbúuli'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td>Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>Maya0470</td>\n",
       "      <td>Tene' ma' jbúuleni'</td>\n",
       "      <td>PERSON:1_PL</td>\n",
       "      <td>To'one' ma' jbúulo'oni'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td>Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>Maya0471</td>\n",
       "      <td>Tene' ma' jbúuleni'</td>\n",
       "      <td>PERSON:2_PL</td>\n",
       "      <td>Te'exe' ma' jbúule'exi'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td>Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>Maya0121</td>\n",
       "      <td>Táan a bin koonol tu k'íiwikil koonol</td>\n",
       "      <td>TYPE:NEG</td>\n",
       "      <td>Ma' táan a bin koonol tu k'íiwikil koonoli'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0121\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td>Id: Maya0121\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>Maya0122</td>\n",
       "      <td>Táan a bin koonol tu k'íiwikil koonol</td>\n",
       "      <td>SUBTYPE:INT</td>\n",
       "      <td>Táan wáaj a bin koonol tu k'íiwikil koonol</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0122\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td>Id: Maya0122\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2675 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                 Source  \\\n",
       "0     Bribri0359                           Pûs kapë'wa̠   \n",
       "1     Bribri0360                           Pûs kapë'wa̠   \n",
       "2     Bribri0361                           Pûs kapë'wa̠   \n",
       "3     Bribri0362                           Pûs kapë'wa̠   \n",
       "4     Bribri0363                           Pûs kapë'wa̠   \n",
       "...          ...                                    ...   \n",
       "2670    Maya0469                    Tene' ma' jbúuleni'   \n",
       "2671    Maya0470                    Tene' ma' jbúuleni'   \n",
       "2672    Maya0471                    Tene' ma' jbúuleni'   \n",
       "2673    Maya0121  Táan a bin koonol tu k'íiwikil koonol   \n",
       "2674    Maya0122  Táan a bin koonol tu k'íiwikil koonol   \n",
       "\n",
       "                           Change  \\\n",
       "0                       ABSNUM:PL   \n",
       "1                        TYPE:NEG   \n",
       "2                   TENSE:PRF_REC   \n",
       "3        TENSE:PRF_REC, ABSNUM:PL   \n",
       "4     TENSE:IPFV_REC, ASPECT:IPFV   \n",
       "...                           ...   \n",
       "2670                  PERSON:3_SI   \n",
       "2671                  PERSON:1_PL   \n",
       "2672                  PERSON:2_PL   \n",
       "2673                     TYPE:NEG   \n",
       "2674                  SUBTYPE:INT   \n",
       "\n",
       "                                           Target language  split  \\\n",
       "0                                   Pûs kapë'ulur   bribri    dev   \n",
       "1                             Pûs kë̀ kapë̀ne̠wa̠   bribri    dev   \n",
       "2                                     Pûs kapówa̠   bribri    dev   \n",
       "3                                    Pûs kapóulur   bribri    dev   \n",
       "4                                    Pûs kapö̀wa̠   bribri    dev   \n",
       "...                                           ...      ...    ...   \n",
       "2670                          Leti'e' ma' jbúuli'     maya  train   \n",
       "2671                      To'one' ma' jbúulo'oni'     maya  train   \n",
       "2672                      Te'exe' ma' jbúule'exi'     maya  train   \n",
       "2673  Ma' táan a bin koonol tu k'íiwikil koonoli'     maya  train   \n",
       "2674   Táan wáaj a bin koonol tu k'íiwikil koonol     maya  train   \n",
       "\n",
       "                                              Formatted  \\\n",
       "0     Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "1     Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "2     Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "3     Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "4     Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "...                                                 ...   \n",
       "2670  Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
       "2671  Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
       "2672  Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
       "2673  Id: Maya0121\\nSource: Táan a bin koonol tu k'í...   \n",
       "2674  Id: Maya0122\\nSource: Táan a bin koonol tu k'í...   \n",
       "\n",
       "                                      Formatted_Covered Predicted Target  \n",
       "0     Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "1     Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "2     Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "3     Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "4     Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "...                                                 ...              ...  \n",
       "2670  Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...                   \n",
       "2671  Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...                   \n",
       "2672  Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...                   \n",
       "2673  Id: Maya0121\\nSource: Táan a bin koonol tu k'í...                   \n",
       "2674  Id: Maya0122\\nSource: Táan a bin koonol tu k'í...                   \n",
       "\n",
       "[2675 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "out_folder = \"preds/chatgpt/chatgpt-smart-context3/\"\n",
    "\n",
    "def test_smart_context(chunk_size, df):\n",
    "    df = df.copy(deep=True)\n",
    "    for language in  ['guarani', 'maya']: #['bribri']\n",
    "        lang_test_size = len(df[(df['language'] == language) & (df['split'] == 'dev')])\n",
    "\n",
    "        for chunk in range(math.ceil(lang_test_size / chunk_size)):\n",
    "            print(f\"Testing indices {chunk*chunk_size} through {(chunk+1)*chunk_size}\")\n",
    "            test_chunk = df[(df['language'] == language) & (df['split'] == 'dev')]['ID'].values[chunk*chunk_size: (chunk+1)*chunk_size]\n",
    "            pred_dict = run_prompt_smart_retrieval(lang=language, test_IDs=test_chunk, log_file=f\"{out_folder}/{language}-smart.log\")\n",
    "            for pred_id, pred_string in pred_dict.items():\n",
    "                df.loc[df['ID'] == pred_id, 'Predicted Target'] = pred_string\n",
    "\n",
    "    df[(df['language'] == 'bribri') & (df['split'] == 'dev')].to_csv(out_folder + \"bribri-dev-preds-smart.tsv\", sep=\"\\t\")\n",
    "    df[(df['language'] == 'guarani') & (df['split'] == 'dev')].to_csv(out_folder + \"guarani-dev-preds-smart.tsv\", sep=\"\\t\")\n",
    "    df[(df['language'] == 'maya') & (df['split'] == 'dev')].to_csv(out_folder + \"maya-dev-preds-smart.tsv\", sep=\"\\t\")\n",
    "\n",
    "    return df\n",
    "\n",
    "preds = test_smart_context(chunk_size=80, df=df)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID                                 Source  \\\n",
      "0     Bribri0359                           Pûs kapë'wa̠   \n",
      "1     Bribri0360                           Pûs kapë'wa̠   \n",
      "2     Bribri0361                           Pûs kapë'wa̠   \n",
      "3     Bribri0362                           Pûs kapë'wa̠   \n",
      "4     Bribri0363                           Pûs kapë'wa̠   \n",
      "...          ...                                    ...   \n",
      "2670    Maya0469                    Tene' ma' jbúuleni'   \n",
      "2671    Maya0470                    Tene' ma' jbúuleni'   \n",
      "2672    Maya0471                    Tene' ma' jbúuleni'   \n",
      "2673    Maya0121  Táan a bin koonol tu k'íiwikil koonol   \n",
      "2674    Maya0122  Táan a bin koonol tu k'íiwikil koonol   \n",
      "\n",
      "                           Change  \\\n",
      "0                       ABSNUM:PL   \n",
      "1                        TYPE:NEG   \n",
      "2                   TENSE:PRF_REC   \n",
      "3        TENSE:PRF_REC, ABSNUM:PL   \n",
      "4     TENSE:IPFV_REC, ASPECT:IPFV   \n",
      "...                           ...   \n",
      "2670                  PERSON:3_SI   \n",
      "2671                  PERSON:1_PL   \n",
      "2672                  PERSON:2_PL   \n",
      "2673                     TYPE:NEG   \n",
      "2674                  SUBTYPE:INT   \n",
      "\n",
      "                                           Target language  split  \\\n",
      "0                                   Pûs kapë'ulur   bribri    dev   \n",
      "1                             Pûs kë̀ kapë̀ne̠wa̠   bribri    dev   \n",
      "2                                     Pûs kapówa̠   bribri    dev   \n",
      "3                                    Pûs kapóulur   bribri    dev   \n",
      "4                                    Pûs kapö̀wa̠   bribri    dev   \n",
      "...                                           ...      ...    ...   \n",
      "2670                          Leti'e' ma' jbúuli'     maya  train   \n",
      "2671                      To'one' ma' jbúulo'oni'     maya  train   \n",
      "2672                      Te'exe' ma' jbúule'exi'     maya  train   \n",
      "2673  Ma' táan a bin koonol tu k'íiwikil koonoli'     maya  train   \n",
      "2674   Táan wáaj a bin koonol tu k'íiwikil koonol     maya  train   \n",
      "\n",
      "                                              Formatted  \\\n",
      "0     Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
      "1     Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
      "2     Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
      "3     Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
      "4     Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
      "...                                                 ...   \n",
      "2670  Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
      "2671  Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
      "2672  Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
      "2673  Id: Maya0121\\nSource: Táan a bin koonol tu k'í...   \n",
      "2674  Id: Maya0122\\nSource: Táan a bin koonol tu k'í...   \n",
      "\n",
      "                                      Formatted_Covered  Predicted Target  \n",
      "0     Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...     Pûs kapë'wa̠n  \n",
      "1     Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...  Pûs kë̀ kapë'wa̠  \n",
      "2     Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...      Pûs kapé'wa̠  \n",
      "3     Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...      Pûs kapë'wé̠  \n",
      "4     Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...     Pûs kapö̀'wa̠  \n",
      "...                                                 ...               ...  \n",
      "2670  Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...                    \n",
      "2671  Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...                    \n",
      "2672  Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...                    \n",
      "2673  Id: Maya0121\\nSource: Táan a bin koonol tu k'í...                    \n",
      "2674  Id: Maya0122\\nSource: Táan a bin koonol tu k'í...                    \n",
      "\n",
      "[2675 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict test data for full-context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing indices 0 through 20\n",
      "CompletionUsage(completion_tokens=431, prompt_tokens=29251, total_tokens=29682)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 20 through 40\n",
      "CompletionUsage(completion_tokens=490, prompt_tokens=29313, total_tokens=29803)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 40 through 60\n",
      "CompletionUsage(completion_tokens=492, prompt_tokens=29280, total_tokens=29772)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 60 through 80\n",
      "CompletionUsage(completion_tokens=532, prompt_tokens=29318, total_tokens=29850)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 80 through 100\n",
      "CompletionUsage(completion_tokens=514, prompt_tokens=29345, total_tokens=29859)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 100 through 120\n",
      "CompletionUsage(completion_tokens=571, prompt_tokens=29375, total_tokens=29946)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 120 through 140\n",
      "CompletionUsage(completion_tokens=557, prompt_tokens=29372, total_tokens=29929)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 140 through 160\n",
      "CompletionUsage(completion_tokens=507, prompt_tokens=29322, total_tokens=29829)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 160 through 180\n",
      "CompletionUsage(completion_tokens=526, prompt_tokens=29347, total_tokens=29873)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 180 through 200\n",
      "CompletionUsage(completion_tokens=573, prompt_tokens=29355, total_tokens=29928)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 200 through 220\n",
      "CompletionUsage(completion_tokens=578, prompt_tokens=29367, total_tokens=29945)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 220 through 240\n",
      "CompletionUsage(completion_tokens=434, prompt_tokens=29243, total_tokens=29677)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 240 through 260\n",
      "CompletionUsage(completion_tokens=489, prompt_tokens=29278, total_tokens=29767)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 260 through 280\n",
      "CompletionUsage(completion_tokens=514, prompt_tokens=29294, total_tokens=29808)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 280 through 300\n",
      "CompletionUsage(completion_tokens=503, prompt_tokens=29296, total_tokens=29799)\n",
      "gpt-4-turbo-2024-04-09\n",
      "Testing indices 300 through 320\n",
      "CompletionUsage(completion_tokens=264, prompt_tokens=28972, total_tokens=29236)\n",
      "gpt-4-turbo-2024-04-09\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Change</th>\n",
       "      <th>Target</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>Formatted</th>\n",
       "      <th>Formatted_Covered</th>\n",
       "      <th>Predicted Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bribri0359</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>ABSNUM:PL</td>\n",
       "      <td>Pûs kapë'ulur</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bribri0360</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TYPE:NEG</td>\n",
       "      <td>Pûs kë̀ kapë̀ne̠wa̠</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bribri0361</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TENSE:PRF_REC</td>\n",
       "      <td>Pûs kapówa̠</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bribri0362</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TENSE:PRF_REC, ABSNUM:PL</td>\n",
       "      <td>Pûs kapóulur</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bribri0363</td>\n",
       "      <td>Pûs kapë'wa̠</td>\n",
       "      <td>TENSE:IPFV_REC, ASPECT:IPFV</td>\n",
       "      <td>Pûs kapö̀wa̠</td>\n",
       "      <td>bribri</td>\n",
       "      <td>dev</td>\n",
       "      <td>Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td>Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>Maya0469</td>\n",
       "      <td>Tene' ma' jbúuleni'</td>\n",
       "      <td>PERSON:3_SI</td>\n",
       "      <td>Leti'e' ma' jbúuli'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td>Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>Maya0470</td>\n",
       "      <td>Tene' ma' jbúuleni'</td>\n",
       "      <td>PERSON:1_PL</td>\n",
       "      <td>To'one' ma' jbúulo'oni'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td>Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>Maya0471</td>\n",
       "      <td>Tene' ma' jbúuleni'</td>\n",
       "      <td>PERSON:2_PL</td>\n",
       "      <td>Te'exe' ma' jbúule'exi'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td>Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>Maya0121</td>\n",
       "      <td>Táan a bin koonol tu k'íiwikil koonol</td>\n",
       "      <td>TYPE:NEG</td>\n",
       "      <td>Ma' táan a bin koonol tu k'íiwikil koonoli'</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0121\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td>Id: Maya0121\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>Maya0122</td>\n",
       "      <td>Táan a bin koonol tu k'íiwikil koonol</td>\n",
       "      <td>SUBTYPE:INT</td>\n",
       "      <td>Táan wáaj a bin koonol tu k'íiwikil koonol</td>\n",
       "      <td>maya</td>\n",
       "      <td>train</td>\n",
       "      <td>Id: Maya0122\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td>Id: Maya0122\\nSource: Táan a bin koonol tu k'í...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2675 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                 Source  \\\n",
       "0     Bribri0359                           Pûs kapë'wa̠   \n",
       "1     Bribri0360                           Pûs kapë'wa̠   \n",
       "2     Bribri0361                           Pûs kapë'wa̠   \n",
       "3     Bribri0362                           Pûs kapë'wa̠   \n",
       "4     Bribri0363                           Pûs kapë'wa̠   \n",
       "...          ...                                    ...   \n",
       "2670    Maya0469                    Tene' ma' jbúuleni'   \n",
       "2671    Maya0470                    Tene' ma' jbúuleni'   \n",
       "2672    Maya0471                    Tene' ma' jbúuleni'   \n",
       "2673    Maya0121  Táan a bin koonol tu k'íiwikil koonol   \n",
       "2674    Maya0122  Táan a bin koonol tu k'íiwikil koonol   \n",
       "\n",
       "                           Change  \\\n",
       "0                       ABSNUM:PL   \n",
       "1                        TYPE:NEG   \n",
       "2                   TENSE:PRF_REC   \n",
       "3        TENSE:PRF_REC, ABSNUM:PL   \n",
       "4     TENSE:IPFV_REC, ASPECT:IPFV   \n",
       "...                           ...   \n",
       "2670                  PERSON:3_SI   \n",
       "2671                  PERSON:1_PL   \n",
       "2672                  PERSON:2_PL   \n",
       "2673                     TYPE:NEG   \n",
       "2674                  SUBTYPE:INT   \n",
       "\n",
       "                                           Target language  split  \\\n",
       "0                                   Pûs kapë'ulur   bribri    dev   \n",
       "1                             Pûs kë̀ kapë̀ne̠wa̠   bribri    dev   \n",
       "2                                     Pûs kapówa̠   bribri    dev   \n",
       "3                                    Pûs kapóulur   bribri    dev   \n",
       "4                                    Pûs kapö̀wa̠   bribri    dev   \n",
       "...                                           ...      ...    ...   \n",
       "2670                          Leti'e' ma' jbúuli'     maya  train   \n",
       "2671                      To'one' ma' jbúulo'oni'     maya  train   \n",
       "2672                      Te'exe' ma' jbúule'exi'     maya  train   \n",
       "2673  Ma' táan a bin koonol tu k'íiwikil koonoli'     maya  train   \n",
       "2674   Táan wáaj a bin koonol tu k'íiwikil koonol     maya  train   \n",
       "\n",
       "                                              Formatted  \\\n",
       "0     Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "1     Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "2     Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "3     Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "4     Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...   \n",
       "...                                                 ...   \n",
       "2670  Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
       "2671  Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
       "2672  Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...   \n",
       "2673  Id: Maya0121\\nSource: Táan a bin koonol tu k'í...   \n",
       "2674  Id: Maya0122\\nSource: Táan a bin koonol tu k'í...   \n",
       "\n",
       "                                      Formatted_Covered Predicted Target  \n",
       "0     Id: Bribri0359\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "1     Id: Bribri0360\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "2     Id: Bribri0361\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "3     Id: Bribri0362\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "4     Id: Bribri0363\\nSource: Pûs kapë'wa̠\\nChange: ...                   \n",
       "...                                                 ...              ...  \n",
       "2670  Id: Maya0469\\nSource: Tene' ma' jbúuleni'\\nCha...                   \n",
       "2671  Id: Maya0470\\nSource: Tene' ma' jbúuleni'\\nCha...                   \n",
       "2672  Id: Maya0471\\nSource: Tene' ma' jbúuleni'\\nCha...                   \n",
       "2673  Id: Maya0121\\nSource: Táan a bin koonol tu k'í...                   \n",
       "2674  Id: Maya0122\\nSource: Táan a bin koonol tu k'í...                   \n",
       "\n",
       "[2675 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def test_full_context_test_data(chunk_size, df):\n",
    "\n",
    "    out_folder = f\"preds/chatgpt/test-results/fc_{chunk_size}\"\n",
    "\n",
    "    df = df.copy(deep=True)\n",
    "    for language in ['maya']:#, 'guarani', 'maya']):\n",
    "        lang_test_size = len(df[(df['language'] == language) & (df['split'] == 'test')])\n",
    "\n",
    "        for chunk in range(math.ceil(lang_test_size / chunk_size)):\n",
    "            print(f\"Testing indices {chunk*chunk_size} through {(chunk+1)*chunk_size}\")\n",
    "            test_chunk = df[(df['language'] == language) & (df['split'] == 'test')]['ID'].values[chunk*chunk_size: (chunk+1)*chunk_size]\n",
    "            pred_dict = run_prompt_full_context(lang=language, test_IDs=test_chunk, log_file=f\"./{language}-test-data.log\")\n",
    "            for pred_id, pred_string in pred_dict.items():\n",
    "                df.loc[df['ID'] == pred_id, 'Predicted Target'] = pred_string\n",
    "\n",
    "    # df[(df['language'] == 'bribri') & (df['split'] == 'test')].to_csv(f\"{out_folder}/bribri-test-preds.tsv\", sep=\"\\t\")\n",
    "    # df[(df['language'] == 'guarani') & (df['split'] == 'test')].to_csv(f\"{out_folder}/guarani-test-preds.tsv\", sep=\"\\t\")\n",
    "            df[(df['language'] == 'maya') & (df['split'] == 'test')].to_csv(f\"{out_folder}/maya-test-preds.tsv\", sep=\"\\t\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "preds = test_full_context_test_data(chunk_size=20, df=df)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output_tsv(lang, preds):\n",
    "\n",
    "    results = preds[(preds['language'] == lang) & (preds['split'] == 'test')]\n",
    "    results = results[[\"ID\", \"Source\", \"Change\", \"Predicted Target\"]]\n",
    "    results.columns = ['ID', 'Source', 'Change', 'Target']\n",
    "    results.to_csv(f\"test-preds/chatgpt/{lang}.tsv\", sep = \"\\t\", index = False)\n",
    "\n",
    "format_output_tsv(\"maya\", preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
