{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "Michael's Version\n",
    "\n",
    "We will try a number of trivial strategies for augmenting data.\n",
    "\n",
    "## 1. Copying Transformation\n",
    "To help model the types of data in the input and output space, let's add rows for every unique source and target sentence where the change is empty, and repeat the sentence back. We can do this for the training sentences and the `Source` values from the dev sentences. This is essentially *lemma copying* from [Yang et al (2022)](https://aclanthology.org/2022.sigmorphon-1.23)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "langs = ['bribri', 'maya', 'guarani']\n",
    "\n",
    "def create_identity_dataframe(lang, test_name=None, header=None):\n",
    "    train_df = pd.read_csv(f\"../data/yoyodyne/{lang}-train.tsv\", delimiter=\"\\t\")\n",
    "    train_df.columns = ['Source', 'Target', 'Change']\n",
    "    sentences = list(set(train_df['Source'].values.tolist() + train_df['Target'].values.tolist()))\n",
    "\n",
    "    if test_name is not None:\n",
    "        test_df = pd.read_csv(f\"../data/yoyodyne/{lang}-{test_name}.tsv\", delimiter=\"\\t\", header=None)\n",
    "        sentences += list(set(test_df[0].values.tolist()))\n",
    "\n",
    "    return pd.DataFrame({'Source': sentences, 'Target': sentences, 'Change': 'NOCHANGE'})\n",
    "\n",
    "for lang in langs:\n",
    "    identity_df = create_identity_dataframe(lang, 'test')\n",
    "    identity_df.to_csv(f\"../data/augmented/{lang}-identity-with-test.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lateral Transformations\n",
    "Our training data includes a number of groups of examples with the same source sentence and the same type of change applied. For example, Maya includes the following:\n",
    "\n",
    "```text\n",
    "Ma' táan in bin ich kooli' [PERSON:2_SI] -> Ma' táan a bin ich kooli'\t\n",
    "Ma' táan in bin ich kooli' [PERSON:3_SI] -> Ma' táan u bin ich kooli'\t\n",
    "```\n",
    "\n",
    "(Here, the source sentence is presumably PERSON:1_SI but we won't utilize that yet)\n",
    "\n",
    "Because the two examples share the same source sentence and feature, it is evident that the following:\n",
    "\n",
    "```text\n",
    "Ma' táan u bin ich kooli [PERSON:2_SI] -> Ma' táan a bin ich kooli'\t\n",
    "```\n",
    "i.e., the third person to second person transformation, is also valid. Likewise, we have:\n",
    "\n",
    "```text\n",
    "Ma' táan a bin ich kooli [PERSON:3_SI] -> Ma' táan u bin ich kooli'\t\n",
    "```\n",
    "i.e., the second person to third person.\n",
    "\n",
    "For each group of source sentences, we can create these **lateral transformations**. This includes when two sentences have exactly the same type of features, but also if one sentence has a superset of the types of changes of the other (since the additional features are originally unmarked/null)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>TYPE1:VALUE5;TYPE3:VALUE6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>TYPE2:VALUE7;TYPE3:VALUE8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>TYPE2:VALUE3;TYPE3:VALUE4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source Target                     Change\n",
       "0      B      D  TYPE1:VALUE5;TYPE3:VALUE6\n",
       "1      C      E  TYPE2:VALUE7;TYPE3:VALUE8\n",
       "2      E      C  TYPE2:VALUE3;TYPE3:VALUE4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df = pd.DataFrame({\n",
    "    'Source': ['A', 'A', 'A', 'A'],\n",
    "    'Target': ['B', 'C', 'D', 'E'],\n",
    "    'Change': [\n",
    "        'TYPE1:VALUE1',\n",
    "        'TYPE2:VALUE3;TYPE3:VALUE4',\n",
    "        'TYPE1:VALUE5;TYPE3:VALUE6',\n",
    "        'TYPE2:VALUE7;TYPE3:VALUE8'\n",
    "    ]\n",
    "})\n",
    "\n",
    "def lateral_augment(df: pd.DataFrame):\n",
    "    # Parse the Change column into a set of TYPE values\n",
    "    def parse_change(change_str):\n",
    "        return {change.split(':')[0] for change in change_str.split(';')}\n",
    "\n",
    "    df['Types'] = df['Change'].apply(parse_change)\n",
    "\n",
    "    def find_matching_rows(df, row_index):\n",
    "        target_types = df.iloc[row_index]['Types']\n",
    "        matching_rows = []\n",
    "        for i, row in df.iterrows():\n",
    "            if i != row_index and target_types.issubset(row['Types']):\n",
    "                matching_rows.append(i)\n",
    "        return matching_rows\n",
    "    \n",
    "    new_sources = []\n",
    "    new_targets = []\n",
    "    new_changes = []\n",
    "\n",
    "    for source_row_index in range(len(df)):\n",
    "        matching_rows = find_matching_rows(df, source_row_index)\n",
    "        # For each matching row, create a new row \n",
    "        for target_row_index in matching_rows:\n",
    "            new_sources.append(df.iloc[source_row_index]['Target'])\n",
    "            new_targets.append(df.iloc[target_row_index]['Target'])\n",
    "            new_changes.append(df.iloc[target_row_index]['Change'])\n",
    "    return pd.DataFrame({'Source': new_sources, 'Target': new_targets, 'Change': new_changes})\n",
    "\n",
    "lateral_augment(toy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lateral_dataframe(lang):\n",
    "    train_df = pd.read_csv(f\"../data/yoyodyne/{lang}-train.tsv\", delimiter=\"\\t\")\n",
    "    augmented_dfs = []\n",
    "    for _, group in train_df.groupby(['Source']):\n",
    "        if (group.size == 1):\n",
    "            continue\n",
    "\n",
    "        augmented_dfs.append(lateral_augment(group.reset_index()))\n",
    "    \n",
    "    return pd.concat(augmented_dfs, axis=0)\n",
    "            \n",
    "for lang in langs:\n",
    "    lateral_df = create_lateral_dataframe(lang)\n",
    "    lateral_df.to_csv(f\"../data/augmented/{lang}-lateral.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
