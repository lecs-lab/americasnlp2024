{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "Michael's Version\n",
    "\n",
    "We will try a number of trivial strategies for augmenting data.\n",
    "\n",
    "## 1. Identity Transformation\n",
    "To help model the types of data in the input and output space, let's add rows for every unique source and target sentence where the change is empty, and repeat the sentence back. We can do this for the training sentences and the `Source` values from the dev sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "langs = ['bribri', 'maya', 'guarani']\n",
    "\n",
    "def create_identity_dataframe(lang):\n",
    "    train_df = pd.read_csv(f\"../data/yoyodyne/{lang}-train.tsv\", delimiter=\"\\t\")\n",
    "    sentences = list(set(train_df['Source'].values.tolist() + train_df['Target'].values.tolist()))\n",
    "\n",
    "    dev_df = pd.read_csv(f\"../data/yoyodyne/{lang}-dev.tsv\", delimiter=\"\\t\")\n",
    "    sentences += list(set(dev_df['Source'].values.tolist()))\n",
    "    return pd.DataFrame({'Source': sentences, 'Target': sentences, 'Change': 'NOCHANGE'})\n",
    "\n",
    "for lang in langs:\n",
    "    identity_df = create_identity_dataframe(lang)\n",
    "    identity_df.to_csv(f\"../data/augmented/{lang}-identity.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
