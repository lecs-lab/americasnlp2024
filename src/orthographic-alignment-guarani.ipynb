{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50ed464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface\n",
      "  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: huggingface\n",
      "Successfully installed huggingface-0.0.1\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Downloading pyarrow-15.0.2-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from datasets) (4.66.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Collecting huggingface-hub>=0.19.4 (from datasets)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\americasnlp2024\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "   ---------------------------------------- 0.0/510.5 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 92.2/510.5 kB 2.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 143.4/510.5 kB 2.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 256.0/510.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 510.5/510.5 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 116.3/116.3 kB 7.1 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "   ---------------------------------------- 0.0/170.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 170.9/170.9 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "   ---------------------------------------- 0.0/388.9 kB ? eta -:--:--\n",
      "   ----------------------------------- --- 358.4/388.9 kB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 388.9/388.9 kB 12.2 MB/s eta 0:00:00\n",
      "Downloading pyarrow-15.0.2-cp310-cp310-win_amd64.whl (24.8 MB)\n",
      "   ---------------------------------------- 0.0/24.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.4/24.8 MB 8.7 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.7/24.8 MB 7.2 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.1/24.8 MB 7.6 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.3/24.8 MB 8.1 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.4/24.8 MB 5.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.7/24.8 MB 6.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.1/24.8 MB 6.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.3/24.8 MB 6.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.7/24.8 MB 6.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.4/24.8 MB 7.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.0/24.8 MB 7.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.6/24.8 MB 8.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.2/24.8 MB 8.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 5.8/24.8 MB 8.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.4/24.8 MB 9.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.7/24.8 MB 8.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 7.4/24.8 MB 9.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.3/24.8 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.6/24.8 MB 10.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.3/24.8 MB 9.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.0/24.8 MB 10.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.0/24.8 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.3/24.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.3/24.8 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.1/24.8 MB 14.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.5/24.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.6/24.8 MB 14.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.4/24.8 MB 14.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.5/24.8 MB 15.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.0/24.8 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.5/24.8 MB 19.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.0/24.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.6/24.8 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.2/24.8 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.7/24.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.8/24.8 MB 25.2 MB/s eta 0:00:00\n",
      "Downloading filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "   ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 134.8/134.8 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, fsspec, filelock, dill, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.3.1\n",
      "    Uninstalling fsspec-2024.3.1:\n",
      "      Successfully uninstalled fsspec-2024.3.1\n",
      "Successfully installed datasets-2.18.0 dill-0.3.8 filelock-3.13.3 fsspec-2024.2.0 huggingface-hub-0.22.2 multiprocess-0.70.16 pyarrow-15.0.2 pyarrow-hotfix-0.6 xxhash-3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311158c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c422eb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bb2332cc394d86b5b4aadf121c85c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a3c2c76d9f4900bba79386deff5b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cc100/gn to C:/Users/matth/.cache/huggingface/datasets/cc100/gn/1.0.0/f0eb694c41a28a8c093b9db6d024dc2186ada300bb33d1d149bdf0481b68ad16...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120a0456fb114273ab3a7a906e187da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.55M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cc100 downloaded and prepared to C:/Users/matth/.cache/huggingface/datasets/cc100/gn/1.0.0/f0eb694c41a28a8c093b9db6d024dc2186ada300bb33d1d149bdf0481b68ad16. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e3109967974fadb81a32712d1ec5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"cc100\",\"gn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f4a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "877133ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72285"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6cee2a",
   "metadata": {},
   "source": [
    "Let's start by figuring out what our possible character sets are between a sample of this data, and the Guarani data in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a989ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "90dc4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "guarani_gold = pd.read_csv(\"../data/yoyodyne/guarani-train.tsv\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f4da5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to make a quick heuristic comparison between our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0c01bdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(sent) for sent in guarani_gold.iloc[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dd7e1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_guarani_sent_len = max([len(sent) for sent in guarani_gold.iloc[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c0f6a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_guarani_sent_len = min([len(sent) for sent in guarani_gold.iloc[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f6c842de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_guarani_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d80ac58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_gold = \" \".join(guarani_gold.iloc[:,0]) + \" \".join(guarani_gold.iloc[:,1])\n",
    "all_text_cc = \" \".join(dataset['train']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6458bdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pa umi kuatiahai apohare. Upéi ojehechaukákuri Mbo'ehára Rafael Dendia ha Juan Ramón Jiménez rembias\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_cc[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d585454d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ke pokã Peẽ napejapómi ogyke pokã Peẽ napejapómi ogyke pokã Peẽ napejapómi ogyke pokã Ko po ojupi Ko'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_gold[400:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4dd73fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a first approximation, let's compare the character sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "367b793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_character_set = set([char for char in all_text_gold])\n",
    "cc_character_set = set([char for char in all_text_cc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f4274ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_to_gold = gold_character_set - cc_character_set\n",
    "len(list(unique_to_gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e37010fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "825"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_to_cc = cc_character_set - gold_character_set\n",
    "len(list(unique_to_cc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd150d9d",
   "metadata": {},
   "source": [
    "Okay, so it seems that the CC data is basically a character superset of the gold standard data we have.\n",
    "\n",
    "Let's check some most common character n-grams in the gold standard data and see if we can find similar words in the CC-100 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c9080847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngrams(full_text, n=3):\n",
    "    n_grams = []\n",
    "    split_text = full_text.split()\n",
    "    for word in split_text:\n",
    "        if len(word) >= n:\n",
    "            n_grams.extend([word[i:i+n] for i in range(len(word) - n + 1)])\n",
    "    \n",
    "    return n_grams\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "90fa65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also normalize the text to lower case\n",
    "\n",
    "all_text_gold = all_text_gold.lower()\n",
    "all_text_cc = all_text_cc.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6100bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "gold_ngrams = build_ngrams(all_text_gold)\n",
    "\n",
    "gold_ngram_count = Counter(gold_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aeb1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f5c09143",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_ngrams = build_ngrams(all_text_cc)\n",
    "\n",
    "cc_ngram_count = Counter(cc_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b0eee87c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gold_top_ngrams = set([x[0] for x in gold_ngram_count.most_common(100)])\n",
    "\n",
    "cc_top_ngrams = set([x[0] for x in cc_ngram_count.most_common(100)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7d6769a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_unique = gold_top_ngrams - cc_top_ngrams\n",
    "len(gold_unique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "67cad3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_unique = cc_top_ngrams - gold_top_ngrams\n",
    "len(cc_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "882e720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({\"CC\": list(sorted(cc_unique)), \"Gold\": list(sorted(gold_unique))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1f29183f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a'e</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>boj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apo</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apy</td>\n",
       "      <td>che</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ara</td>\n",
       "      <td>dom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ava</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ave</td>\n",
       "      <td>ere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ba’</td>\n",
       "      <td>gyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cha</td>\n",
       "      <td>ha’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e'ẽ</td>\n",
       "      <td>hín</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>egu</td>\n",
       "      <td>iku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ehe</td>\n",
       "      <td>imi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eko</td>\n",
       "      <td>jap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ete</td>\n",
       "      <td>jur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gue</td>\n",
       "      <td>kur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gui</td>\n",
       "      <td>kuá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ich</td>\n",
       "      <td>mo’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kue</td>\n",
       "      <td>ndo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mba</td>\n",
       "      <td>ogy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ogu</td>\n",
       "      <td>oja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>oje</td>\n",
       "      <td>oju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>oñe</td>\n",
       "      <td>ore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pet</td>\n",
       "      <td>osa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>por</td>\n",
       "      <td>tem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ran</td>\n",
       "      <td>uap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rek</td>\n",
       "      <td>uku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>uar</td>\n",
       "      <td>ura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>upe</td>\n",
       "      <td>uri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ára</td>\n",
       "      <td>yke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>áva</td>\n",
       "      <td>ína</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>éva</td>\n",
       "      <td>ñei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ñe'</td>\n",
       "      <td>’ek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ñe’</td>\n",
       "      <td>’uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CC Gold\n",
       "0   a'e  are\n",
       "1   and  boj\n",
       "2   apo  bot\n",
       "3   apy  che\n",
       "4   ara  dom\n",
       "5   ava  end\n",
       "6   ave  ere\n",
       "7   ba’  gyk\n",
       "8   cha  ha’\n",
       "9   e'ẽ  hín\n",
       "10  egu  iku\n",
       "11  ehe  imi\n",
       "12  eko  jap\n",
       "13  ete  jur\n",
       "14  gue  kur\n",
       "15  gui  kuá\n",
       "16  ich  mo’\n",
       "17  kue  ndo\n",
       "18  mba  ogy\n",
       "19  ogu  oja\n",
       "20  oje  oju\n",
       "21  oñe  ore\n",
       "22  pet  osa\n",
       "23  por  tem\n",
       "24  ran  uap\n",
       "25  rek  uku\n",
       "26  uar  ura\n",
       "27  upe  uri\n",
       "28  ára  yke\n",
       "29  áva  ína\n",
       "30  éva  ñei\n",
       "31  ñe'  ’ek\n",
       "32  ñe’  ’uk"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd9bad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0131996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what about what they have in common?\n",
    "\n",
    "common_ngrams = gold_top_ngrams - gold_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1afa1b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agu',\n",
       " 'aku',\n",
       " 'ape',\n",
       " 'apy',\n",
       " 'are',\n",
       " 'a’e',\n",
       " 'eku',\n",
       " 'emb',\n",
       " 'emo',\n",
       " 'end',\n",
       " 'ere',\n",
       " 'ete',\n",
       " 'gua',\n",
       " 'ha’',\n",
       " 'ich',\n",
       " 'iko',\n",
       " 'iku',\n",
       " 'jap',\n",
       " 'kua',\n",
       " 'kur',\n",
       " 'kué',\n",
       " 'mbi',\n",
       " 'mbo',\n",
       " 'mby',\n",
       " 'nda',\n",
       " 'nde',\n",
       " 'ndu',\n",
       " 'ogu',\n",
       " 'ohe',\n",
       " 'omb',\n",
       " 'omo',\n",
       " 'ret',\n",
       " 'umi',\n",
       " 'upé',\n",
       " 'uri',\n",
       " 'uér',\n",
       " 'ára',\n",
       " 'éra',\n",
       " 'ñan',\n",
       " 'ñem'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "08d0ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_foreign_character(text):\n",
    "    for char in text:\n",
    "        if char not in gold_character_set:\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "15de7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try filtering out sentences in the CC data where foreign characters exist--that might at least get us to somewhere closer\n",
    "\n",
    "cc_words = all_text_cc.split()\n",
    "cc_okay_words = [word for word in cc_words if not contains_foreign_character(word)]\n",
    "cc_text = \" \".join(cc_okay_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "41acecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_ngrams_cleaned = build_ngrams(cc_text)\n",
    "\n",
    "cc_ngram_count_cleaned = Counter(cc_ngrams_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d6dc1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_top_ngrams_cleaned = set([x[0] for x in cc_ngram_count_cleaned.most_common(100)])\n",
    "\n",
    "\n",
    "cc_unique = cc_top_ngrams_cleaned - gold_top_ngrams\n",
    "gold_unique = gold_top_ngrams - cc_top_ngrams_cleaned\n",
    "\n",
    "df = pd.DataFrame.from_dict({\"CC\": list(sorted(cc_unique)), \"Gold\": list(sorted(gold_unique))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "46f9d174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "common_ngrams = cc_top_ngrams_cleaned - cc_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1c959b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agu',\n",
       " 'aku',\n",
       " 'ape',\n",
       " 'apy',\n",
       " 'are',\n",
       " 'asy',\n",
       " 'a’e',\n",
       " 'eku',\n",
       " 'emb',\n",
       " 'emo',\n",
       " 'end',\n",
       " 'ere',\n",
       " 'ete',\n",
       " 'gua',\n",
       " 'ha’',\n",
       " 'ich',\n",
       " 'iko',\n",
       " 'iku',\n",
       " 'jap',\n",
       " 'kua',\n",
       " 'kur',\n",
       " 'kué',\n",
       " 'mbi',\n",
       " 'mbo',\n",
       " 'mby',\n",
       " 'nda',\n",
       " 'nde',\n",
       " 'ndu',\n",
       " 'ogu',\n",
       " 'ohe',\n",
       " 'omb',\n",
       " 'omo',\n",
       " 'ret',\n",
       " 'umi',\n",
       " 'upé',\n",
       " 'uér',\n",
       " 'ára',\n",
       " 'éra',\n",
       " 'ñan',\n",
       " 'ñem'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dc11a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_words_with_and = [word for word in cc_okay_words if 'jap' in word]\n",
    "\n",
    "gold_words_with_and = [word for word in all_text_gold.split(\" \") if 'jap' in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "37081969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['najajapómi',\n",
       " 'napejapói',\n",
       " 'napejapómi',\n",
       " 'ndajajapói',\n",
       " 'nderejapói',\n",
       " 'nderejapókuri',\n",
       " 'nderejapómi',\n",
       " 'ndojapói',\n",
       " 'nojapopami',\n",
       " 'nojapómi',\n",
       " 'norojapómi',\n",
       " 'ojapopa',\n",
       " 'ojapopami',\n",
       " 'ojapopata',\n",
       " 'ojapopava’ekue',\n",
       " 'pejapomi',\n",
       " 'rejapo']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(set(gold_words_with_and)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1728eac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ajapómi',\n",
       " 'ojapóma',\n",
       " 'ojapómahina',\n",
       " 'ojapómakatu',\n",
       " 'ojapómaneraka’e',\n",
       " 'ojapómava',\n",
       " 'ojapómi',\n",
       " 'ojejapóma',\n",
       " 'ojejapóma,',\n",
       " 'ojejapómajepi',\n",
       " 'ojejapómava',\n",
       " 'ojejapómi',\n",
       " 'ojejapómiva’erâ',\n",
       " 'ojejapómiva’erã']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(set([word for word in cc_okay_words if \"japóm\" in word])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ec325",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "60533d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"hembi’ukuéra\" == \"hembi’ukuéra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57838e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "475c4227",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ombojerekuri\n",
      "\n",
      "kutuhakuéra\n",
      "\n",
      "ombojerekuri\n",
      "\n",
      "kutuhakuéra\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "napejapómi\n",
      "\n",
      "napejapómi\n",
      "\n",
      "napejapómi\n",
      "\n",
      "napejapómi\n",
      "\n",
      "napejapómi\n",
      "\n",
      "napejapómi\n",
      "\n",
      "napejapómi\n",
      "\n",
      "temirendukuéra\n",
      "\n",
      "temirendukuéra\n",
      "\n",
      "temirendukuéra\n",
      "\n",
      "temirendukuéra\n",
      "\n",
      "temirendukuéra\n",
      "\n",
      "ndombovuta\n",
      "\n",
      "ndombovuta\n",
      "\n",
      "ndombovuta\n",
      "\n",
      "ndombovuta\n",
      "\n",
      "ndombovuta\n",
      "\n",
      "apekuéra\n",
      "\n",
      "apekuéra\n",
      "\n",
      "apekuéra\n",
      "\n",
      "apekuéra\n",
      "\n",
      "apekuéra\n",
      "\n",
      "naiñemoñaréi\n",
      "\n",
      "naiñemoñaréi\n",
      "\n",
      "naiñemoñaréi\n",
      "\n",
      "naiñemoñaréi\n",
      "\n",
      "naiñemoñaréi\n",
      "\n",
      "naiñemoñaréi\n",
      "\n",
      "nañemoingeta\n",
      "\n",
      "nañemoingeta\n",
      "\n",
      "nañemoingeta\n",
      "\n",
      "nañemoingeta\n",
      "\n",
      "nañemoingeta\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojurata\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojuramo’ãi\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojurata\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojuramo’ãi\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojurata\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojuramo’ãi\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojurata\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojuramo’ãi\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojurata\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojuramo’ãi\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ajavými\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "ajavými\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "ajavými\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "ajavými\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "ajavými\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "ajavými\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "ajavými\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "ndorokuave’ẽi\n",
      "\n",
      "ndorokuave’ẽi\n",
      "\n",
      "ndorokuave’ẽi\n",
      "\n",
      "ndorokuave’ẽi\n",
      "\n",
      "ndorokuave’ẽi\n",
      "\n",
      "ndorokuave’ẽi\n",
      "\n",
      "ndorokuave’ẽi\n",
      "\n",
      "reñembosarái\n",
      "\n",
      "reñembosarái\n",
      "\n",
      "reñembosarái\n",
      "\n",
      "reñembosarái\n",
      "\n",
      "reñembosarái\n",
      "\n",
      "reñembosarái\n",
      "\n",
      "reñembosarái\n",
      "\n",
      "ndombojaruita\n",
      "\n",
      "ndombojaruita\n",
      "\n",
      "ndombojaruita\n",
      "\n",
      "ndombojaruita\n",
      "\n",
      "ndombojaruita\n",
      "\n",
      "nderemoheñói\n",
      "\n",
      "nderemoheñói\n",
      "\n",
      "nderemoheñói\n",
      "\n",
      "nderemoheñói\n",
      "\n",
      "nombotujaimi\n",
      "\n",
      "ndombyaimi\n",
      "\n",
      "nombotujaimi\n",
      "\n",
      "ndombyaimi\n",
      "\n",
      "nombotujaimi\n",
      "\n",
      "ndombyaimi\n",
      "\n",
      "nombotujaimi\n",
      "\n",
      "ndombyaimi\n",
      "\n",
      "nombotujaimi\n",
      "\n",
      "ndombyaimi\n",
      "\n",
      "nombotujaimi\n",
      "\n",
      "ndombyaimi\n",
      "\n",
      "nombotujaimi\n",
      "\n",
      "ndombyaimi\n",
      "\n",
      "hovy’ûvare\n",
      "\n",
      "hovy’ûvare\n",
      "\n",
      "hovy’ûvare\n",
      "\n",
      "hovy’ûvare\n",
      "\n",
      "ohenduká\n",
      "\n",
      "ohenduká\n",
      "\n",
      "ohenduká\n",
      "\n",
      "ohenduká\n",
      "\n",
      "ohenduká\n",
      "\n",
      "okũmbymi\n",
      "\n",
      "okũmbymi\n",
      "\n",
      "okũmbymi\n",
      "\n",
      "okũmbymi\n",
      "\n",
      "okũmbymi\n",
      "\n",
      "ojapopami\n",
      "\n",
      "ojapopami\n",
      "\n",
      "ojapopami\n",
      "\n",
      "ojapopami\n",
      "\n",
      "ojapopami\n",
      "\n",
      "rasyha’e\n",
      "\n",
      "ndombojereikuri\n",
      "\n",
      "kutuhakuéra\n",
      "\n",
      "ombojerehina\n",
      "\n",
      "kutuhakuéra\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "ndombotyi\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "ombotyta\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "ombotyva’ekue\n",
      "\n",
      "mombe’ukuéra\n",
      "\n",
      "najajapómi\n",
      "\n",
      "norojapómi\n",
      "\n",
      "napejapói\n",
      "\n",
      "napejapói\n",
      "\n",
      "pejapomi\n",
      "\n",
      "nojapómi\n",
      "\n",
      "nderejapómi\n",
      "\n",
      "ojupíta\n",
      "\n",
      "ndojupíri\n",
      "\n",
      "ojupíhina\n",
      "\n",
      "ikóni\n",
      "\n",
      "mbóikuera\n",
      "\n",
      "oñorairõmi\n",
      "\n",
      "noñorairõi\n",
      "\n",
      "temirendu\n",
      "\n",
      "temirendukuéra\n",
      "\n",
      "omongakuaata\n",
      "\n",
      "temirendukuéra\n",
      "\n",
      "ndomongakuaai\n",
      "\n",
      "temirendukuéra\n",
      "\n",
      "temirendukuéra\n",
      "\n",
      "omongakuaami\n",
      "\n",
      "ndombovúi\n",
      "\n",
      "ombovuta\n",
      "\n",
      "ndombovúi\n",
      "\n",
      "pohanohárakuera\n",
      "\n",
      "ndombovúita\n",
      "\n",
      "ndombovúiva’ekue\n",
      "\n",
      "ndombojárai\n",
      "\n",
      "apekuéra\n",
      "\n",
      "rembojára\n",
      "\n",
      "apekuéra\n",
      "\n",
      "ambojára\n",
      "\n",
      "apekuéra\n",
      "\n",
      "ombojárata\n",
      "\n",
      "apekuéra\n",
      "\n",
      "apekuéra\n",
      "\n",
      "aikuaá\n",
      "\n",
      "oñemoñaréi\n",
      "\n",
      "naiñemoñaréita\n",
      "\n",
      "naiñañemoñaréi\n",
      "\n",
      "nairoñemoñaréi\n",
      "\n",
      "naipeñemoñaréi\n",
      "\n",
      "ndoñemoñaréi\n",
      "\n",
      "ndapurahéi\n",
      "\n",
      "apurahéihina\n",
      "\n",
      "apurahéitta\n",
      "\n",
      "ta’yrakuérape\n",
      "\n",
      "ta’yrakuérape\n",
      "\n",
      "ita’ýrakuérape\n",
      "\n",
      "nañemoingei\n",
      "\n",
      "añemoingeta\n",
      "\n",
      "nañemoingeimi\n",
      "\n",
      "nareñemoingeta\n",
      "\n",
      "noroñemoingeta\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ojurata\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojurai\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojuraimi\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojuraiva’ekue\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ñeimo’ã’ỹva\n",
      "\n",
      "ndojurai\n",
      "\n",
      "aovevekuéra\n",
      "\n",
      "ndajavýimi\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "ajavýimi\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "ajavýta\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "rejavýimi\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "jajavýimi\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "rojavýimi\n",
      "\n",
      "iñeikotevẽva\n",
      "\n",
      "akuápe\n",
      "\n",
      "rokuave’ẽ\n",
      "\n",
      "ndorokuave’ẽi\n",
      "\n",
      "ndorokuave’ẽi\n",
      "\n",
      "ikóni\n",
      "\n",
      "ndorokuave’ẽimi\n",
      "\n",
      "ndañakuave’ẽi\n",
      "\n",
      "ndaikuave’ẽi\n",
      "\n",
      "ndereikuave’ẽi\n",
      "\n",
      "reñembosarái\n",
      "\n",
      "nereñembosaráiri\n",
      "\n",
      "añembosarái\n",
      "\n",
      "reñembosarái\n",
      "\n",
      "ikóni\n",
      "\n",
      "reñembosaráita\n",
      "\n",
      "reñembosarái\n",
      "\n",
      "nosapukái\n",
      "\n",
      "osapukáita\n",
      "\n",
      "osapukáiva’ekue\n",
      "\n",
      "akirirĩ.\n",
      "\n",
      "rekirirĩ.\n",
      "\n",
      "ndokirirĩ.\n",
      "\n",
      "okirirĩta.\n",
      "\n",
      "ndomo’âi\n",
      "\n",
      "pemo’â\n",
      "\n",
      "penderembi’ukuéra.\n",
      "\n",
      "remo’â\n",
      "\n",
      "nderembi’ukuéra.\n",
      "\n",
      "amo’â\n",
      "\n",
      "cherembi’ukuéra.\n",
      "\n",
      "ikóni\n",
      "\n",
      "ojupita\n",
      "\n",
      "ndojupirí\n",
      "\n",
      "ndachemba’ei\n",
      "\n",
      "mba’éta\n",
      "\n",
      "ombojaruita\n",
      "\n",
      "nderembojarui\n",
      "\n",
      "ndombojarui\n",
      "\n",
      "ndombojaruita\n",
      "\n",
      "ndambojaruita\n",
      "\n",
      "oguapýva’ekue\n",
      "\n",
      "remoheñói\n",
      "\n",
      "nderemoheñóikuri\n",
      "\n",
      "ndañamoheñói\n",
      "\n",
      "ndomoheñoi\n",
      "\n",
      "ombotujaimi\n",
      "\n",
      "ombyaimi\n",
      "\n",
      "ndombotujaikuri\n",
      "\n",
      "ndombyaikuri\n",
      "\n",
      "nderembotujáimi\n",
      "\n",
      "nerembyaimi\n",
      "\n",
      "ndañambotujáimi\n",
      "\n",
      "ndañambyaimi\n",
      "\n",
      "ombotujáta\n",
      "\n",
      "ombyaíta\n",
      "\n",
      "ndombotujáiva’ekue\n",
      "\n",
      "ndombyaiva’ekue\n",
      "\n",
      "ndambotujamoái\n",
      "\n",
      "ndambyaimoái\n",
      "\n",
      "reikomi\n",
      "\n",
      "hovy’ûvare\n",
      "\n",
      "ndoikomi\n",
      "\n",
      "hovy’ûvare\n",
      "\n",
      "hovy’ûvare\n",
      "\n",
      "aikomi\n",
      "\n",
      "hovy’ûvare\n",
      "\n",
      "ndoipurui\n",
      "\n",
      "oipuruta\n",
      "\n",
      "ho’uta\n",
      "\n",
      "ndohenduká\n",
      "\n",
      "emohenduká\n",
      "\n",
      "pemohenduká\n",
      "\n",
      "peê.\n",
      "\n",
      "añanita\n",
      "\n",
      "añanihínava’ekue\n",
      "\n",
      "(nde)\n",
      "\n",
      "reñanihínakuri\n",
      "\n",
      "(ñande)\n",
      "\n",
      "ñañanihínakuri\n",
      "\n",
      "okũmby\n",
      "\n",
      "okũmbyta\n",
      "\n",
      "ñakũmbýimi\n",
      "\n",
      "akũmbymi\n",
      "\n",
      "ndokũmbýimi\n",
      "\n",
      "nderejapókuri\n",
      "\n",
      "ojapopami\n",
      "\n",
      "nojapopami\n",
      "\n",
      "ojapopata\n",
      "\n",
      "ojapopava’ekue\n",
      "\n",
      "cherasy\n",
      "\n",
      "cherasy\n",
      "\n",
      "ndacherásyi\n",
      "\n",
      "rasypota\n",
      "\n",
      "nderasy\n",
      "\n",
      "rorasy\n",
      "\n",
      "penderasy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#final reasonable sanity check -- are there wordforms in the original data that do not appear at all in the other corpus?\n",
    "\n",
    "for word in all_text_gold.split(\" \"):\n",
    "    if word not in cc_okay_words:\n",
    "        print(f\"{word}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0a9d217c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_guarani_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060246cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ddc97d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "guarani_data_filtered = dataset['train']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2ad0d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "guarani_data_filtered = [x.strip() for x in guarani_data_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b0fbf3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "guarani_data_filtered = [x for x in guarani_data_filtered if not contains_foreign_character(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f324d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "guarani_data_filtered = [x for x in guarani_data_filtered if len(x)<= max_guarani_sent_len * 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "37bb27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "guarani_data_filtered = [x for x in guarani_data_filtered if len(x) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2301b016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6676"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(guarani_data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a8d7896f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tekotevẽ oñembo’e tekoha reheguáre opárupi ha opaichave.',\n",
       " 'oñeñangareko haguã tekoháre, terã ojoko haguã tembiapo, ombyaiva terã ombyaiséva tekoha, ha',\n",
       " 'porã mba’épepa ombyaí aiguéne tekohápe.',\n",
       " 'oiméva, ’y opáva peguarã terã ikatúva opavave oiporu, avei umi ’y yvyguypegua umichagua',\n",
       " 'ndivéi, ambue Tetãmini ha umi táva, ojererekóne tenondérupi umi aguĩgua.',\n",
       " 'Ojeikove haguã oñekotevẽ katuete ’ýre.',\n",
       " 'Tetãmini mburuvicha oñangareko va’erã opaite yjyvýre.',\n",
       " 'Tetãmini ha táva mba’e.',\n",
       " 'Tetãmini ha táva mokõive ikatuha peve ojapo omoingouka va’erã yvy jeporu ha avei',\n",
       " 'Tembiapo tekotevẽva ojapo va’erã tavaregua omoporãve haguã tekove, ome’ẽ va’erã umi']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guarani_data_filtered[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e633fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some other cleanup \n",
    "guarani_data_filtered = [x.lower() for x in guarani_data_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d1994afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_gold_ngrams = build_ngrams(all_text_gold.lower(), n=2)\n",
    "unique_gold_ngrams = list(set(unique_gold_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "38e716d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_foreign_trigram(sentence):\n",
    "    sent_ngrams = build_ngrams(sentence, n=2)\n",
    "    for ngram in sent_ngrams:\n",
    "        if ngram not in unique_gold_ngrams and '.' not in ngram:\n",
    "            print(ngram)\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0b1337b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c1420bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8fa347aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "guarani_data_filtered = list(set([x.capitalize() for x in guarani_data_filtered]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "82a36394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3516"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(guarani_data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "56739a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = random.sample(guarani_data_filtered, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ed97ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into some DF\n",
    "\n",
    "df_dict = {\"Source\": sampled, \"Target\": sampled, \"Change\": [\"NOCHANGE\"]*len(sampled)}\n",
    "\n",
    "df_to_save = pd.DataFrame.from_dict(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fd723f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save.to_csv(\"../data/augmented/guarani-identity-externalcorp.tsv\", sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff7e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
